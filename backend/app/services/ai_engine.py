import os
import git
import re
import gc
import traceback
from typing import Tuple
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI  # âœ… æ”¹æˆæ–°ç‰ˆåŒ¯å…¥

# âœ… Load API key
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("âŒ OpenAI API Key æœªæ‰¾åˆ°ï¼Œè«‹ç¢ºèª .env è¨­å®šæ­£ç¢ºï¼")

# âœ… Constants
GITLAB_REPO_URL = "https://gitlab.com/chen88088/mlops_dag_template.git"
LOCAL_DAG_FOLDER = "gitlab_dags"
VECTOR_DB_FOLDER = "dag_vector_db"

# âœ… Global cache
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
faiss_index = None

# âœ… å»ºç«‹ OpenAI å®¢æˆ¶ç«¯
client = OpenAI(api_key=OPENAI_API_KEY)

# âœ… Clone or update Git repo
def sync_gitlab_repo():
    if os.path.exists(LOCAL_DAG_FOLDER):
        print("âœ… GitLab Repo å·²å­˜åœ¨ï¼Œæ­£åœ¨æ›´æ–°...")
        repo = git.Repo(LOCAL_DAG_FOLDER)
        repo.remotes.origin.pull()
    else:
        print("âœ… æ­£åœ¨å¾ GitLab Clone Repo...")
        git.Repo.clone_from(GITLAB_REPO_URL, LOCAL_DAG_FOLDER)
    print("âœ… DAG æ¨¡æ¿å·²åŒæ­¥å®Œæˆï¼")

# âœ… å»ºç«‹ FAISS å‘é‡åº«
def build_faiss_index():
    global faiss_index
    dag_texts = []
    for filename in os.listdir(LOCAL_DAG_FOLDER):
        if filename.endswith(".py"):
            with open(os.path.join(LOCAL_DAG_FOLDER, filename), "r", encoding="utf-8") as f:
                dag_texts.append(f.read())
    faiss_index = FAISS.from_texts(dag_texts, embeddings)
    faiss_index.save_local(VECTOR_DB_FOLDER)
    print(f"âœ… å»ºç«‹ FAISS æˆåŠŸï¼Œè¼‰å…¥äº† {len(dag_texts)} å€‹æ¨¡æ¿")

# âœ… è¼‰å…¥ FAISSï¼ˆåªåšä¸€æ¬¡ï¼‰
def load_faiss():
    global faiss_index
    if not faiss_index:
        faiss_index = FAISS.load_local(VECTOR_DB_FOLDER, embeddings, allow_dangerous_deserialization=True)
        print("âœ… FAISS Index è¼‰å…¥å®Œæˆ")

# âœ… æ ¸å¿ƒä¸»æµç¨‹ï¼šæŸ¥è©¢ + AI å›æ‡‰
def run_ai_assist(question: str, dag_code: str = "") -> Tuple[str, str]:
    try:
        load_faiss()
        docs = faiss_index.similarity_search(question, k=1)
        best_dag = docs[0].page_content

        user_dag = f"ä½¿ç”¨è€…ç›®å‰çš„ DAG ç¨‹å¼ç¢¼ï¼š\n{dag_code}" if dag_code.strip() else ""

        prompt = (
            "ä½ æ˜¯ä¸€ä½å°ˆç²¾æ–¼ Airflow çš„å·¥ç¨‹å¸«ã€‚è«‹æ ¹æ“šä¸‹åˆ—å…©æ®µè³‡è¨Šï¼Œæ•´åˆå‡ºä¸€å€‹ç¬¦åˆæå•éœ€æ±‚çš„å®Œæ•´ DAGï¼š\n\n"
            f"- GitLab ä¸­æœ€ç›¸ä¼¼çš„ DAG ç¯„ä¾‹ï¼š\n{best_dag}\n\n"
            f"{user_dag}\n"
            f"è«‹ä½ ï¼š\n"
            f"1. æ ¹æ“šéœ€æ±‚ '{question}' å¢åŠ å¿…è¦ä»»å‹™ã€‚\n"
            "2. ä¿®æ”¹ owner ç‚º 'jerryChen'ã€‚\n"
            "3. åŠ ä¸Š email é€šçŸ¥ 'chen88088@gmail.com'ã€‚\n"
            "4. è‹¥æœ‰åŸå§‹ DAG ç¨‹å¼ç¢¼ï¼Œè«‹ä¿ç•™å…¶ä»»å‹™çµæ§‹èˆ‡ç›¸ä¾é †åºï¼Œä¸¦æ•´åˆå»ºè­°ã€‚\n"
            "5. è«‹ç›´æ¥è¼¸å‡ºå®Œæ•´ Python ç¨‹å¼ç¢¼ï¼Œä¸è¦é™„åŠ èªªæ˜ï¼Œä¸è¦çœç•¥ä»»ä½•ä»»å‹™èˆ‡å…§å®¹ï¼Œè«‹å®Œæ•´ä¿ç•™æ¯ä¸€è¡Œç¨‹å¼ç¢¼ã€‚"
        )

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆç²¾æ–¼ Airflow çš„å·¥ç¨‹å¸«ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=3000
        )

        answer = response.choices[0].message.content.strip()

        if "```python" in answer:
            code_match = re.search(r"```python\n(.*?)```", answer, re.DOTALL)
            code = code_match.group(1).strip() if code_match else answer
        else:
            code = answer

        return answer, code

    except Exception as e:
        print("âŒ AI åŠ©ç†ç™¼ç”ŸéŒ¯èª¤ï¼š", e)
        traceback.print_exc()
        return "âš ï¸ AI åŠ©ç†å‡ºéŒ¯äº†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", ""

    finally:
        gc.collect()

# âœ… åˆå§‹å»ºæ§‹ï¼ˆåªåšä¸€æ¬¡ï¼‰
if __name__ == "__main__":
    sync_gitlab_repo()
    build_faiss_index()
    full, code = run_ai_assist("åŠ å…¥ Slack é€šçŸ¥", "")
    print("\nğŸ’¬ Response:\n", full)
    print("\nğŸ§¾ DAG code:\n", code)
